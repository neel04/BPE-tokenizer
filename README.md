# BPE

Training exercise to learn C++.

This implements training the [Byte Pair Encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) algorithm.

This algorithm is used to compress data by replacing the most frequent pair of bytes with a new byte. Often used in LLMs such as [GPT-2](https://en.wikipedia.org/wiki/GPT-2) for tokenizing UTF-8 text.

Credits to [Karpathy's explanation](https://www.youtube.com/watch?v=zduSFxRajkE) of the algorithm.